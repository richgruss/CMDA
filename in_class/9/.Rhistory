age <- c(1,2,3,4,5,6,7,8)
weight <- c(5,6,7,2,3,4,9,8)
mean(weight)
mean(age)
cor(age,weight)
plot(age,weight)
weight <- c(12,16,19,32,55,100,200,600)
plot(age,weight)
cor(age,weight)
help.start()
cwd
pwd
setwd('/Users/rgruss/git/CMDA/in_class/9')
#synthetic variables; no header; no names
data29 <- read.csv('train.csv', header = F, sep = ',')
head(data29)
data29Labels <- read.csv('trainLabels.csv', header = F, sep = ',')
head(data29Labels)
#I will have to get a testing and training set
#change the name of the variable in Labels
names(data29Labels) <- "target"
names(data29Labels)
#put data and labels together
all <- cbind(data29, data29Labels)
head(all)
rm(data29)
rm(data29Labels)
#create a random variable and use it to extract a 50% training
#and 50% test set
all$gp <- runif(dim(all)[1])
train <- subset(all, all$gp > 0.5)
test <- subset(all, all$gp <= 0.5)
#Make sure we know what we got
names(train)
head(train)
y <- factor(train$target)
head(y)
x <- paste("V", 1:20, sep="")
x
x1 <- paste(x, collapse = "+")
x1
fmla <- paste("y",x1,sep = '~')
print(fmla)
log_reg <- glm(fmla, data = train, family = "binomial")
print summary(log_reg)
summary(log_reg)
setwd('/Users/rgruss/git/CMDA/in_class/9')
#synthetic variables; no header; no names
data29 <- read.csv('train.csv', header = F, sep = ',')
head(data29)
data29Labels <- read.csv('trainLabels.csv', header = F, sep = ',')
head(data29Labels)
#I will have to get a testing and training set
#change the name of the variable in Labels
names(data29Labels) <- "target"
names(data29Labels)
#put data and labels together
all <- cbind(data29, data29Labels)
head(all)
rm(data29)
rm(data29Labels)
#create a random variable and use it to extract a 50% training
#and 50% test set
all$gp <- runif(dim(all)[1])
train <- subset(all, all$gp > 0.5)
test <- subset(all, all$gp <= 0.5)
#Make sure we know what we got
names(train)
head(train)
#fit logistic regression to train set
#make response a factor variable with values 0/1
#corresponding to the two classes we want to use
y <- factor(train$target)
head(y)
#Use only the first 20 variables in the train set; 40 slow down
#and might create computational issues with this method
#Use a shortcut to create the logistic regression formula
x <- paste("V", 1:20, sep="")
x
x1 <- paste(x, collapse = "+")
x1
fmla <- paste("y",x1,sep = '~')
print(fmla)
#Train the logistic regression model
log_reg <- glm(fmla, data = train, family = "binomial")
train$pred <- predict(log_reg, newdata = train, type = "response")
head(train$pred)
head(y)
table(y)
sum(train$pred)
library(ggplot2)
ggplot(train, aes(x=pred, color=factor(target), linetype=factor(target))) +  geom_density()
setwd('/Users/rgruss/git/CMDA/in_class/9')
library(shiny)
runApp("App.1")
install.packages("shiny")
library(shiny)
runApp("App.1")
